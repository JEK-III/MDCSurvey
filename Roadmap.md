# Roadmap

* Researchers who publish useful data should be acknowledged
* that requires accepted metrics for data impact / value / whatever
* citation counts are the most common for papers, but there are also altmetrics

several efforts underway:
* *RDA bibliometrics WG (https://rd-alliance.org/group/rdawds-publishing-data-bibliometrics-wg/case-statement/rdawds-publishing-data-bibliometrics-wg)
* *NISO Altmetric WG is considering data (http://www.niso.org/topics/tl/altmetrics_initiative/)

Making Data Count: NSF-funded collaboration between CDL, PLOS, DataONE
* work is ongoing
* Goal is to define a set of metrics and develop a tool
* to do that, we surveyed researchers and repo. staff on their needs/interestes WRT metrics

Methods
* *online surveys distributed via social media and listservs

* Researcher demographics:
* *N=247
* *78% academic
* *57% US, 14% UK
* *53% biology, 17% environmental science, 10% social science



##OPD
*Data discovery
* *63% "definitely" use two or more methods to look for data
* *Use of disciplinary databases, the literature, and general-purpose search engines is roughly similar (59%, 58%, and 51% definite respectively)
* *Social-ish methods are much less well used (but private communications wasn't addressed)

*Quality
* *good documentation is the most important factor (52% #1)
* *surprisingly, reuse is the least important factor (48% #5)
* *consistent with PLOS paper (Kratz and Strasser, 2015)

##own data
* 94 (38%) shared most/all of their data in some way.
* 4 (2%) didn't share any data by any of the provided channels.
* Database/repo had the most respondents saying most/all 52 (21%)
* email had the most respondents sharing some (163, 66%); only 22 (9%) hadn't shared any data via email

who?
* not surprisingly, names & contact info are most interesting ()


*Impact
* *Citations overwhelmingly the first choice (85% #1)
* *Downloads the second (64% %2)
* *Pageviews last at 60% least interesting.
* #1 preferred method of receiving credit in (Enke et al., 2012) (71%)
* #1 preferred method of receiving credit in our survey (75%)			
* “details of publications generated using the data” #1 used (71%) in EAGDA (Bobrow et al., 2014)



* Repo. demographics:
* *N=73
* *64% academic, 22% government
* *72% US, 11% UK

* Metrics tracked and exposed
* *Downloads the most tracked (85%)
* *Views second (66%)
* *Citations to datasets (the most desireable to researchers) 23%

* Many fewer exposed via API or displayed on item page than tracked
* *30% downloads
* *27% views
* *11% citations

Repo interest
* *citations the most interesting to 61%
* *landing pages the least to 51%

*Practical conclusions
* *citations are the most valuable to everyone
* *repos should expose stats downloads and citations
* *views and links are less important
* *data citation is good, collecting that info is good

* previous survey found citations to be the most useful measure of impact (Kratz & Strasser, 2015)