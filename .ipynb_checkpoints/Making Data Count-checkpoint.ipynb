{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Making Data Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In November and December of 2014, we conducted a pair of online surveys of researchers and data managers (i.e., database or repository staff), asking questions about data sharing, discovery, and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "from math import sqrt\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "import seaborn as sns\n",
    "\n",
    "#pylab.rcParams['figure.figsize'] = (14.0, 6.0)\n",
    "sns.set_style(\"white\", \n",
    "              {'font.sans-serif': ['Helevetica', 'Liberation Sans', \n",
    "                                   'Bitstream Vera Sans', 'sans-serif'],\n",
    "               'axes.linewidth': 0,\n",
    "               'xtick.direction': 'in',\n",
    "               'xtick.major.size': 8.0})\n",
    "\n",
    "LABEL_WIDTH = 25\n",
    "sns.axes_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Scheme to consolidate subdisciplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "DISCIPLINE_MAP = {'-Anthropology' : 'Social science',\n",
    "                  '-Archaeology' : 'Archaeology',\n",
    "                  '-Area studies' : 'Social science',\n",
    "                  '-Economics' : 'Social science',\n",
    "                  '-Political science' : 'Social science',\n",
    "                  '-Psychology' : 'Social science',\n",
    "                  '-Sociology' : 'Social science',\n",
    "                  '-Astronomy' : 'Space science',\n",
    "                  '-Astrophysics' : 'Space science',\n",
    "                  '-Environmental Science' : 'Environmental science',\n",
    "                  '-Geology' : 'Earth science',\n",
    "                  '-Oceanography' : 'Environmental science',\n",
    "                  '-Planetary science' : 'Earth science',\n",
    "                  '-Biochemistry' : 'Biology',\n",
    "                  '-Bioinformatics' : 'Biology',\n",
    "                  '-Biology' : 'Biology',\n",
    "                  '-Evolutionary Biology' : 'Biology',\n",
    "                  '-Neurobiology' : 'Biology',\n",
    "                  'Social science' : 'Social science',\n",
    "                  'Space science' : 'Space science',\n",
    "                  'Earth science' : 'Earth science',\n",
    "                  'Life science' : 'Biology',\n",
    "                  'Chemistry' : 'Physical science',\n",
    "                  'Physics' : 'Physical science',\n",
    "                  'Computer science' : 'Computer science',\n",
    "                  'Mathematics' : 'Mathematics',\n",
    "                  'Information science' : 'Information science',\n",
    "                  'Other' : 'Other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Misc. utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def tuple_normalize(counts, n_responses):\n",
    "    return map(lambda x: float(x) / n_responses * 100, counts)\n",
    "\n",
    "def interval_to_error(confidence_interval, center):\n",
    "    \"\"\"\n",
    "    confidence_interval (tuple): low, high relative to the origin\n",
    "    center: (int, float): measured value (e.g., mean)\n",
    "    returns the ci as a tuple relative to the center (i.e., minus, plus the mean)\n",
    "    \"\"\"\n",
    "    low = center - confidence_interval[0]\n",
    "    high = confidence_interval[1] - center\n",
    "    #return tuple(map(lambda x: (float(x) - center), confidence_interval))\n",
    "    return (low, high)\n",
    "    \n",
    "def split_interval(interval):\n",
    "    \"\"\"\n",
    "    split a confidence interval tuple and return as a 2-element Series\n",
    "    \"\"\"\n",
    "    return pd.Series(interval, index= ['low','high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Bootstrap functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_percentile_ci(data, n_samples=100000, alpha=0.05, stat_function=np.sum):\n",
    "    \"\"\"\n",
    "    Calculates a confidence interval for True/False count data and returns a tuple (low, high) \n",
    "    \n",
    "    data: (numpy array) of bools to resample\n",
    "    num_samples: (int) number of times to resample\n",
    "    alpha: (float) 1 - desired confidence interval  \n",
    "    \"\"\"\n",
    "    n_responses = len(data)\n",
    "    # get num_samples resampled arrays (of length n) of valid indicies for data\n",
    "    indicies = np.random.randint(0, n_responses, (n_samples, n_responses))\n",
    "    \n",
    "    # generate sorted array of desired stat in each resampled array\n",
    "    stats = [stat_function(data[x]) for x in indicies]\n",
    "    stats.sort()\n",
    "\n",
    "    # return stats at the edge of the 2.5 and 97.5 percentiles\n",
    "    return (stats[int((alpha/2.0)*n_samples)], stats[int((1-alpha/2.0)*n_samples)])\n",
    "\n",
    "\n",
    "def bootstrap_basic_ci(data, n_samples=100000, alpha=0.05, stat_function=np.sum):\n",
    "    \"\"\"\n",
    "    Calculates a confidence interval for True/False count data and returns a tuple (low, high) \n",
    "    \n",
    "    data: (numpy array) of bools to resample\n",
    "    num_samples: (int) number of times to resample\n",
    "    alpha: (float) 1 - desired confidence interval  \n",
    "    \"\"\"\n",
    "    double_observed = 2 * stat_function(data)\n",
    "    high, low = bootstrap_percentile_ci(data, n_samples=n_samples, alpha=alpha, stat_function=stat_function)\n",
    "\n",
    "    return (double_observed - low, double_observed - high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Graphing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_cdl_style(fig):\n",
    "    fig.set_ylabel('')\n",
    "    sns.despine(ax=fig, left=True)\n",
    "    # get rid of weird dashed line\n",
    "    fig.lines[0].set_visible(False) \n",
    "    \n",
    "    #set font sizes\n",
    "    fig.tick_params(axis='x', width=2, labelsize=14, color='#808080')\n",
    "    fig.tick_params(axis='y', labelsize=16)\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def graph_likert(questions, answers, interval_color='#808080'):\n",
    "    \n",
    "    collected_counts = pd.DataFrame(index=answers)\n",
    "    stats = pd.DataFrame(index=questions.columns,columns=['mean', 'ci'])\n",
    "\n",
    "    # set up dict for converstion from likert scale (e.g., 1-5) to 0-100%\n",
    "    number_of_answers = len(answers) \n",
    "    answer_to_value = dict(zip(answers, np.arange(number_of_answers)/float(number_of_answers - 1)*100)) \n",
    "\n",
    "    for column in questions.columns:\n",
    "        collected_counts[column] = questions[column].value_counts().dropna()\n",
    "\n",
    "        #scale responses to go from 0 to 100\n",
    "        likert_values = questions[column].dropna().map(answer_to_value)\n",
    "\n",
    "        #cacluate mean and 95% confidence interval\n",
    "        stats['mean'].loc[column] = likert_values.mean() \n",
    "        stats['ci'].loc[column] = bootstrap_basic_ci(np.array(likert_values), stat_function=np.mean)\n",
    "        \n",
    "    #sort stats and collected_counts by the mean   \n",
    "    stats = stats.sort_index(axis=0, by='mean', ascending=True)\n",
    "    collected_counts = collected_counts.T.reindex(index=stats.index)\n",
    "    collected_counts = collected_counts.div(collected_counts.sum(1).astype(float)/100, axis = 0)\n",
    "    \n",
    "    #convert absolute interval values to distance below and above the observed value\n",
    "    for index in stats.index.values:\n",
    "        stats['ci'].loc[index] = interval_to_error(stats['ci'].loc[index], stats['mean'].loc[index])\n",
    "    \n",
    "    #split interval tuples into 2 element Series\n",
    "    stats['ci'] = stats['ci'].apply(split_interval)\n",
    "    \n",
    "    collected_counts.index = [ '\\n'.join(wrap(i, LABEL_WIDTH)) for i in collected_counts.index ]\n",
    "    \n",
    "    #plot percentages of each response\n",
    "    fig = collected_counts.plot(kind='barh', stacked=True, grid=False, \n",
    "                                color=sns.color_palette(\"Blues\", len(collected_counts.columns)),\n",
    "                                xlim = (0,100), edgecolor='w', linewidth=2) \n",
    "    \n",
    "    # plot mean and 95% confidence interval\n",
    "    fig.plot(stats['mean'], np.arange(len(stats)), marker='o', color='w',axes=fig, \n",
    "             markersize=25, markeredgewidth=0, linewidth=0)\n",
    "    \n",
    "    fig.errorbar(stats['mean'].as_matrix(), np.arange(len(stats)), xerr=stats['ci'],\n",
    "                 fmt='none', ecolor=interval_color, alpha=0.65, elinewidth=2, capsize=12, capthick=2)\n",
    "    \n",
    "    fig.legend(bbox_to_anchor=(0., -0.02, 1., -0.03), loc='upper left', ncol=number_of_answers, mode=\"expand\",\n",
    "                    borderaxespad=0., fontsize=14)\n",
    "    \n",
    "    apply_cdl_style(fig)\n",
    "    \n",
    "    fig.get_figure().set_size_inches(14.0, 2 * len(collected_counts.index))\n",
    "\n",
    "    return fig , collected_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def graph_checkbox(question, bar_color='#08519c', interval_color='#808080'):\n",
    "    #split_checkbox = responses[question].dropna()\n",
    "\n",
    "    # checkbox_responses== DataFrame of bools where index=individual respondents, columns=answer choices\n",
    "    #checkbox_responses = expand_checkbox(split_checkbox, answers)\n",
    "    checkbox_responses = question.applymap(pd.notnull)\n",
    "    \n",
    "    # sum checked boxes in each column; response_counts== Series with values=sums, index=answer choices\n",
    "    response_counts = checkbox_responses.sum()\n",
    "    \n",
    "    # resample and sum from each column to bootstrap a confidence interval\n",
    "    # count_confidence_intervals== Series with values= tuples (low, high), index=answer choices\n",
    "    count_confidence_intervals = checkbox_responses.apply(lambda x: bootstrap_basic_ci(np.array(x)))\n",
    "        \n",
    "    #normalize response_counts to percentage of total respondents to the question and sort\n",
    "    response_counts = response_counts.apply(lambda x: float(x) / len(checkbox_responses) * 100)\n",
    "    response_counts.sort(ascending=True)\n",
    "    \n",
    "    #normalize confidence intervals to percentages and sort\n",
    "    count_confidence_intervals = count_confidence_intervals.apply(tuple_normalize, args=([len(checkbox_responses)]))\n",
    "    count_confidence_intervals = count_confidence_intervals.reindex(index=response_counts.index)\n",
    "\n",
    "    \n",
    "    #convert absolute interval values to distance below and above the observed value\n",
    "    for index in count_confidence_intervals.index.values:\n",
    "        count_confidence_intervals.loc[index] = interval_to_error(count_confidence_intervals.loc[index], \n",
    "                                                                  response_counts.loc[index])\n",
    "            \n",
    "    #split interval tuples into 2 element Series\n",
    "    count_confidence_intervals = count_confidence_intervals.apply(split_interval)\n",
    "    \n",
    "    response_counts.index = [ '\\n'.join(wrap(i, LABEL_WIDTH)) for i in response_counts.index ]\n",
    "\n",
    "    \n",
    "    fig = response_counts.plot(kind='barh', \n",
    "                               color='#08519c',\n",
    "                               edgecolor='w', grid=False, xlim=(0,100), fontsize=14)\n",
    "    \n",
    "    fig.errorbar(response_counts.as_matrix(), np.arange(len(response_counts)), \n",
    "                 xerr=count_confidence_intervals.T.as_matrix(),\n",
    "                 fmt='none', ecolor=interval_color, alpha=0.65, elinewidth=2, capsize=12, capthick=2)\n",
    "    \n",
    "    \n",
    "    apply_cdl_style(fig)\n",
    "\n",
    "    fig.get_figure().set_size_inches(14.0, 2 * len(response_counts.index))\n",
    "    \n",
    "    return fig, response_counts, count_confidence_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Researchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "r_responses = pd.read_csv('MDC_Researchers.tsv', \n",
    "                          sep='\\t',\n",
    "                          header=[0,1], \n",
    "                          index_col=0,\n",
    "                          tupleize_cols=True)\n",
    "\n",
    "# drop blank rows (ignoring 1st column, which is required)\n",
    "r_responses.dropna(axis=0, how='all', subset=r_responses.columns[1:], inplace=True)\n",
    "\n",
    "r_responses.columns = pd.MultiIndex.from_tuples(r_responses.columns, names=['question', 'subquestion'])\n",
    "r_responses.sort_index(axis=1, inplace=True)\n",
    "\n",
    "r_responses['Which best describes your discipline?', 'Response'] = (\n",
    "    r_responses['Which best describes your discipline?', 'Response'].map(DISCIPLINE_MAP, na_action='Ignore'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "DEMOGRAPHICS = ['Which best describes your employer/institution?', \n",
    "                'Where is your employer/institution located?', \n",
    "                'What is the highest degree you hold?', \n",
    "                'Which best describes your role?', \n",
    "                'Which best describes your discipline?']\n",
    "\n",
    "print(\"N= \" + str(len(r_responses.index)))\n",
    "\n",
    "for column in DEMOGRAPHICS:\n",
    "    count = r_responses[column, 'Response'].value_counts()\n",
    "    percentages = 100 * count.apply(lambda x: float(x) / count.sum())\n",
    "    display(pd.DataFrame([count, percentages], index=['count', 'percent']).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 247 respondents completed the researcher survey. Most (78%) are employed by academic institutions. The United States (57%) and United Kingdom (14%) are easily the best represented countries. We received responses from across the academic career spectrum: principle investigators, post-docs, and grad students are all well represented. Biology is the most popular domain (53%), but environmental (17%) and social (10%) science are also significantly represented.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How frequently do you use data from public sources to accomplish each of the following? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "FREQUENCIES = ['Never', 'Occasionally', 'Often']\n",
    "sources_graph, sources_table = graph_likert(r_responses['How frequently do you use data from public sources to accomplish each of the following?<br>(e.g., data in a public database or journal article supplemental material)'], \n",
    "                               FREQUENCIES)\n",
    "plt.savefig('mdc_use.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survey respondents most frequently reused public data as support for their own data collection– either before (to inform data collection) or after (to support interpretation). However, the number who did \"often\" reuse data to reach the main conclusions (27.8%) is still quite signficant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reuse_data = r_responses['How frequently do you use data from public sources to accomplish each of the following?<br>(e.g., data in a public database or journal article supplemental material)']\n",
    "never_reuse_count = reuse_data.apply(lambda x: x == 'Never').all(axis=1).value_counts()\n",
    "never_reuse_percent = never_reuse_count.apply(lambda x: 100 * float(x) / never_reuse_count.sum())\n",
    "print(str(never_reuse_count[True]) + \" (\" + str(never_reuse_percent[True]) + \n",
    "      \"%) respondents answered 'Never' to all options.\")\n",
    "\n",
    "often_reuse_count = reuse_data.apply(lambda x: x == 'Often').any(axis=1).value_counts()\n",
    "often_reuse_percent = often_reuse_count.apply(lambda x: 100 * float(x) / often_reuse_count.sum())\n",
    "print(str(often_reuse_count[True]) + \" (\" + str(often_reuse_percent[True]) + \n",
    "      \"%) respondents answered 'Often' to at least one option.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When looking for public data to use, how likely you are to search in each of the following ways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LIKELIHOODS = ['No chance', 'Possible', 'Definitely']\n",
    "graph_likert(r_responses['When looking for public data to use, how likely you are to search in each of the following ways?<br><em>If you never use external data, please answer hypothetically.</em>'], \n",
    "             LIKELIHOODS) \n",
    "plt.savefig('mdc_discovery.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most respondents search for data in multiple ways: through links from the literature, disciplinary databases, and general-purpose internet search. More personal reliance on other researchers (via social media or discussion forums) is much less common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_method = r_responses['When looking for public data to use, how likely you are to search in each of the following ways?<br><em>If you never use external data, please answer hypothetically.</em>']\n",
    "definite_methods = search_method.apply(lambda x : x == 'Definitely').sum(axis=1).value_counts().sort_index()\n",
    "definite_methods = definite_methods.apply(lambda x: float(x) / definite_methods.sum() * 100)\n",
    "dm_fig = definite_methods.plot(kind='bar', color='#08519c', edgecolor='w', grid=False, ylim=(0,100), fontsize=16, rot=0,\n",
    "                               title='How many methods would you \"definitely\" use?')\n",
    "sns.despine(ax=dm_fig)\n",
    "print(str(definite_methods[2:].sum()) + '% \"definitely\" use 2 or more methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A majority (63%) of respondents use multiple methods to search for data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please rank the importance of the following for estimating a dataset's quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMPORTANCE_LEVELS = ['5 (Least important)', '4', '3', '2', '1 (Most important)']\n",
    "graph_likert(r_responses[\"Please rank the importance of the following for estimating a dataset's quality (e.g., when deciding whether to download it).<br><em>Please rank items from most to least important.</em>\"], \n",
    "             IMPORTANCE_LEVELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data quality was most frequently estimated through thoroughness of the associated documentation. Somewhat surprisingly, reuse was the least important indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What proportion of your data have you shared in each of the following ways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PROPORTIONS = ['None', 'Some of it', 'Most/all of it']\n",
    "\n",
    "\"\"\"\n",
    "Responses to \"Any means at all\" generally make no sense (e.g., 44 of the 48 respondents who said they shared none of their \n",
    "data by any means also said that they shared some or most of their data through one of the other means. \n",
    "Consequently, I am dropping that question from the analysis.\"\n",
    "\"\"\"\n",
    "\n",
    "sharing_method = r_responses['What proportion of your data have you shared in each of the following ways?'].copy()\n",
    "sharing_method.drop('Any means at all', axis=1, inplace=True)\n",
    "\n",
    "graph_likert(sharing_method, PROPORTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More respondents (90%) have shared data by email than any other method. However, respondents who shared most or all of their data were more likely to do so via a database or repository (24%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sharing_method = responses['What proportion of your data have you shared in each of the following ways?']\n",
    "shared_all_data = sharing_method.apply(lambda x : x == 'Most/all of it').any(axis=1)\n",
    "fig, table = graph_likert(sharing_method[shared_all_data], PROPORTIONS)\n",
    "\n",
    "print(str(shared_all_data.sum()) + ' (' + (str(100. * shared_all_data.sum()/shared_all_data.size)) + \n",
    "      '%) shared \"most/all\" of their data by some means')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(r_responses.info(verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shared_no_data = sharing_method.apply(lambda x : x == 'None').all(axis=1)\n",
    "shared_no_data.sum() / 247.\n",
    "#sharing_method[sharing_method['Any means at all'] == 'None']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How interested you would be to know each of the following about users of your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INTEREST_LEVELS = ['5 (Least interesting)', '4', '3', '2', '1 (Most interesting)']\n",
    "graph_likert(r_responses['How interested you would be to know each of the following about <strong>users<br></strong> of your data?<br><em>Please rank items from most to least interesting.</em>'], \n",
    "             INTEREST_LEVELS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How interested you would be to know each of the following about how your data is used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_likert(r_responses['How interested you would be to know each of the following about <strong>how<br></strong> your data is used?<br><em>Please rank items from most to least interesting.</em>'], \n",
    "             INTEREST_LEVELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How interested you would be to know each of the following about the impact of your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INTEREST_LEVELS_FOUR = ['4 (Least interesting)', '3', '2', '1 (Most interesting)']\n",
    "graph_likert(r_responses['How interested you would be to know each of the following about the impact of your data?<br><em>Please rank items from most to least interesting.</em>'], \n",
    "             INTEREST_LEVELS_FOUR)\n",
    "plt.savefig('mdc_impact.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citations remain the preferred currency of academic credit, as the first choice of 85.5% of respondents. Download count is a clear second choice (by 64.5%). Links and landing page views were both much less popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dm_responses = pd.read_csv('MDC_Managers.tsv', \n",
    "                        sep='\\t',\n",
    "                        header=[0,1], \n",
    "                        index_col=0,\n",
    "                        tupleize_cols=True)\n",
    "\n",
    "# drop blank rows (ignoring 1st column, which is required)\n",
    "dm_responses.dropna(axis=0, how='all', subset=dm_responses.columns[1:], inplace=True)\n",
    "\n",
    "dm_responses.columns = pd.MultiIndex.from_tuples(dm_responses.columns, names=['question', 'subquestion'])\n",
    "dm_responses.sort_index(axis=1, inplace=True)\n",
    "\n",
    "dm_responses['Which best describes your discipline?', 'Response'] = (\n",
    "    dm_responses['Which best describes your discipline?', 'Response'].map(DISCIPLINE_MAP, na_action='Ignore'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "DEMOGRAPHICS = ['Which best describes your employer/institution?', \n",
    "                'Where is your employer/institution located?', \n",
    "                'What is the highest degree you hold?', \n",
    "                'Which best describes your discipline?']\n",
    "\n",
    "print(\"N= \" + str(len(dm_responses.index)))\n",
    "\n",
    "for column in DEMOGRAPHICS:\n",
    "    count = dm_responses[column, 'Response'].value_counts()\n",
    "    percentages = 100 * count.apply(lambda x: float(x) / count.sum())\n",
    "    display(pd.DataFrame([count, percentages], index=['count', 'percent']).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What metrics / statistics do you currently track?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_checkbox(dm_responses['What metrics / statistics do you currently track?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracked_metrics = dm_responses['What metrics / statistics do you currently track?'].copy()\n",
    "tracked_metrics.drop('Other (please specify)', axis=1, inplace=True)\n",
    "tracked_fig, tracked_table, tracked_interval = graph_checkbox(tracked_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracked_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant majority (84.9%) of repositories track downloads. Relatively few (23.3%) track citations to datasets or the repository as a whole (21.9%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What metrics / statistics do you currently expose? (e.g., on landing pages or via API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_checkbox(dm_responses['What metrics / statistics do you currently expose?<br>(e.g., on landing pages or via API)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exposed_metrics = dm_responses['What metrics / statistics do you currently expose?<br>(e.g., on landing pages or via API)'].copy()\n",
    "exposed_metrics.drop('Other (please specify)', axis=1, inplace=True)\n",
    "exposed_fig, exposed_table, exposed_interval = graph_checkbox(exposed_metrics, bar_color='#6baed6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most repositories do not expose any metrics/statistics. Of those that do, downloads (30.1%) and views (23.3%) are the most common. All metrics are collected by a significant number of repositories that do not expose them; 64.5% of the repositories that track downloads don't expose them; 52.9% of the repositories that track citations to individual datasets don't expose them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exposed_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exposed_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_metrics = {'tracked' : tracked_table,\n",
    "                    'exposed' : exposed_table}\n",
    "combined_df = pd.DataFrame(combined_metrics)\n",
    "fig= combined_df.plot(kind='barh', color=sns.color_palette(\"Blues\", 2), edgecolor='w', grid=False, xlim=(0,100), fontsize=14)\n",
    "fig.legend(loc=4,frameon=False, fontsize=16.)\n",
    "\n",
    "fig.get_figure().set_size_inches(14.0, 2 * len(tracked_table.index))\n",
    "\n",
    "fig.errorbar(tracked_table.as_matrix(), np.arange(len(tracked_interval)) + 0.125, \n",
    "             xerr=tracked_interval.T.as_matrix(),\n",
    "             fmt='none', ecolor='#808080', alpha=0.65, elinewidth=2, capsize=6, capthick=2)\n",
    "\n",
    "fig.errorbar(exposed_table.as_matrix(), np.arange(len(exposed_interval)) - 0.125, \n",
    "             xerr=exposed_interval.T.as_matrix(),\n",
    "             fmt='none', ecolor='#808080', alpha=0.65, elinewidth=2, capsize=6, capthick=2)\n",
    "apply_cdl_style(fig)\n",
    "\n",
    "plt.savefig('mdc_practice.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exposed_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exposed_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What information do you require data users to supply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_checkbox(dm_responses['What information do you require data users to supply?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responding repositories were evenly split (at 46.6%) between requiring data users to supply their real name and requiring no information at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_info = dm_responses['What information do you require data users to supply?']\n",
    "real_name_required = user_info['Real name'].apply(lambda x: x == 'Real name')\n",
    "graph_checkbox(user_info[real_name_required])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you currently use the information you collect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_checkbox(dm_responses['How do you currently use the information you collect?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common (56.2%) application for data metrics is as evidence of the value of the repository to funders. However, they are also used by many to inform internal decisions, such as by 46.6% to set priorities and 38.4% to inform collection development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INTERNAL_USES = [u'Inform collection development', u'Inform deaccession decisions', \n",
    "                 u'Set levels of service', u'Set priorities']\n",
    "\n",
    "internal_use = dm_responses['How do you currently use the information you collect?'][INTERNAL_USES].any(axis=1).value_counts()\n",
    "internal_use.apply(lambda x: float(x) / internal_use.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "65.8% of respondents use the information they collect to inform at least one internal decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How interested you would be to know each of the following about users of the data you hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_likert(dm_responses['How interested you would be to know each of the following about <strong>users</strong> of the data you hold?<br><em>Please rank items from most to least interesting.</em>'], \n",
    "             INTEREST_LEVELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a clear interest in knowning what disciplines or research communities the repository is serving; 67.3% chose it as the most interesting option. All the others were a roughly similar mix, execpt, perhaps, for clickstreams, which were the first choice of 16.4% of repository managers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How interested you would be to know each of the following about how the data you hold is used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_likert(dm_responses['How interested you would be to know each of the following about <strong>how</strong> the data you hold is used?<br><em>Please rank items from most to least interesting.</em>'],\n",
    "             INTEREST_LEVELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How interested you would be to know each of the following about the impact of the data you hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INTEREST_LEVELS_SEVEN = ['7 (Least interesting)', '6', '5', '4', '3', '2', '1 (Most interesting)']\n",
    "graph_likert(dm_responses['How interested you would be to know each of the following about the <strong>impact</strong> of the data you hold?<br><em>Please rank items from most to least interesting.</em>'], \n",
    "             INTEREST_LEVELS_SEVEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was the case with rearchers, citations are the most desireable measure of impact as the first choice of 61.1% of respondents. In contrast to this purely scholarly measure, \"real-world\" impact was the second most desireable, but was the first choice of a much smaller percentage (23.2%) of respondents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly relevant to metrics:\n",
    "\n",
    "* Citations remain the preferred currency of scholarly prestige. Citation counts are the most valued measure of impact by both reasearchers and repository staff.\n",
    "\n",
    "* As a measure of impact, download counts are securely in second place in researcher's minds, and many more repositories currently track downloads than citations (85% vs. 23%). In the near term, downloads are an attractive metric in terms of availability.\n",
    "\n",
    "* Many repositories collect stats that they don't expose.\n",
    "\n",
    "Researcher data use and discovery behavior:\n",
    "\n",
    "* Researchers are using other people's data primarily in a supporting role– either before or after their own data collection.\n",
    "\n",
    "* Researchers look for data in muliple ways; the literature, disciplinary databases, and general purpose search are each used by a majority of researchers.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
